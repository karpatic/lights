{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio\n",
    "> A brief description of Meyda features\n",
    "\n",
    "- keywords: ['meyda', 'audio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links and Their Descriptions\n",
    "\n",
    "**[MusicBeam](https://www.musicbeam.org/)**: Open-source music visualizer for live shows.  \n",
    "**[Flutopedia - Sound Color](http://www.flutopedia.com/sound_color.htm)**: Explains the concept of \"sound color\" (timbre) in music.  \n",
    "**[Beat Detection Using Web Audio](http://joesul.li/van/beat-detection-using-web-audio/)**: Tutorial on detecting beats in audio using the Web Audio API.  \n",
    "**[W3C Web NFC](https://w3c.github.io/web-nfc/)**: Official documentation for the Web NFC API (Near Field Communication in browsers).  \n",
    "**[Chrome Extensions Developer Guide](https://developer.chrome.com/extensions/devguide)**: Guide for building Chrome browser extensions.  \n",
    "**[Capture MediaStream from Canvas/Video](https://developers.google.com/web/updates/2016/10/capture-stream)**: Google guide on capturing media streams from canvas or video elements.  \n",
    "**[MDN getUserMedia API](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)**: Documentation for accessing camera/microphone in the browser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Feature Analysis Overview  \n",
    "**Library**: [Meyda - Audio Feature Extraction](https://meyda.js.org/)\n",
    "\n",
    "---\n",
    "\n",
    "## What Is \"The Signal\"?\n",
    "\n",
    "The *signal* is a stream of audio samples‚Äîa time-ordered array of values (typically `Float32Array`) representing the amplitude of sound pressure over time.  \n",
    "Each value typically ranges between **-1.0 and 1.0**, with `0.0` representing silence or neutral pressure.\n",
    "\n",
    "---\n",
    "\n",
    "## What Is the Time Domain?\n",
    "\n",
    "The **time domain** is the representation of sound as it varies over **time**.  \n",
    "It‚Äôs how waveforms are stored and visualized‚Äîamplitude on the y-axis, time on the x-axis.\n",
    "\n",
    "All audio originates in the time domain. Time-domain features directly analyze these raw waveforms without translating them into frequency components.\n",
    "\n",
    "---\n",
    "\n",
    "## Time-Domain Features\n",
    "\n",
    "**RMS (Root Mean Square)**  \n",
    "- **How it works**:  \n",
    "  1. Square each sample (removes sign, emphasizes larger values).  \n",
    "  2. Take the average of those squares (mean).  \n",
    "  3. Take the square root of that mean (brings it back to the original unit).  \n",
    "\n",
    "- **Why it correlates with perceived loudness**:  \n",
    "  RMS approximates the **power** of the waveform, and louder sounds have more power.  \n",
    "  It doesn‚Äôt account for human hearing sensitivity across frequencies, but it gives a good rough estimate of amplitude-based loudness.\n",
    "\n",
    "---\n",
    "\n",
    "**ZCR (Zero Crossing Rate)**  \n",
    "- **What is a zero-crossing?**  \n",
    "  When the signal value **changes sign**, i.e., it moves from positive to negative or vice versa.  \n",
    "  Example: going from `+0.2` to `-0.3` crosses zero.\n",
    "\n",
    "- **Why it's useful**:  \n",
    "  - **Percussive** sounds: chaotic, irregular oscillations ‚Üí high ZCR variance.  \n",
    "  - **Pitched** sounds: periodic waveforms ‚Üí stable ZCR.\n",
    "\n",
    "**Energy**  \n",
    "- Similar to RMS, but omits the square root.  \n",
    "- Sums the squared amplitude values over time; indicates the total \"work\" or \"intensity\" of the signal.\n",
    "\n",
    "---\n",
    "\n",
    "## What Is the Spectral Domain?\n",
    "\n",
    "The **spectral (or frequency) domain** represents **how much energy is present at different frequencies** rather than at different time points.  \n",
    "This is obtained using the **Fourier Transform (FFT)**, which decomposes the signal into a set of sine waves at various frequencies.\n",
    "\n",
    "Spectral features help answer: *\"What frequencies are present in the sound?\"* and *\"How is the energy distributed among them?\"*\n",
    "\n",
    "---\n",
    "\n",
    "## Spectral Features\n",
    "\n",
    "**Amplitude Spectrum**  \n",
    "The magnitude of the FFT; shows which frequencies are present and their intensity.\n",
    "\n",
    "**Power Spectrum**  \n",
    "Amplitude spectrum squared; emphasizes strong frequency components.\n",
    "\n",
    "**Spectral Centroid**  \n",
    "The weighted average frequency; a measure of ‚Äúbrightness.‚Äù\n",
    "\n",
    "**Spectral Flatness**  \n",
    "Measures tonality vs noisiness. Flatness near 1 = white noise; near 0 = tonal signal.\n",
    "\n",
    "**Spectral Flux**  \n",
    "Quantifies the change between successive spectra. High flux = dynamic/rough sounds.\n",
    "\n",
    "**Spectral Slope**  \n",
    "Linear regression on the spectrum; shows whether energy trends toward low or high frequencies.\n",
    "\n",
    "**Spectral Rolloff**  \n",
    "The frequency below which 99% of energy resides.\n",
    "\n",
    "**Spectral Spread**  \n",
    "How widely the energy is distributed around the centroid.\n",
    "\n",
    "**Spectral Skewness**  \n",
    "Asymmetry of the energy distribution.\n",
    "\n",
    "**Spectral Kurtosis**  \n",
    "Peakedness; high values imply tonal/pointy spectra.\n",
    "\n",
    "**Chroma**  \n",
    "Energy content mapped onto 12 pitch classes (C, C‚ôØ, ..., B).\n",
    "\n",
    "---\n",
    "\n",
    "## Perceptual Features\n",
    "\n",
    "These account for how humans **actually hear** (nonlinear, frequency-sensitive).\n",
    "\n",
    "**Loudness (Bark Scale)**  \n",
    "Better matches human perception than RMS; uses 24 critical bands of hearing.\n",
    "\n",
    "**Perceptual Spread**  \n",
    "Distribution of energy across Bark bands; corresponds to perceived richness.\n",
    "\n",
    "**Perceptual Sharpness**  \n",
    "Emphasizes high frequencies; reflects how \"snappy\" a sound feels.\n",
    "\n",
    "**MFCC (Mel-Frequency Cepstral Coefficients)**  \n",
    "Captures timbre and perceptual pitch on a Mel scale; used heavily in speech/music recognition.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Perceptual Features Differ\n",
    "\n",
    "Human hearing is nonlinear and frequency-selective:\n",
    "\n",
    "| Feature             | Raw (Physical)        | Perceptual (Human-Centered)        |\n",
    "|---------------------|------------------------|-------------------------------------|\n",
    "| Loudness            | RMS, Energy            | Bark-scale Loudness                |\n",
    "| Spread              | Spectral Spread        | Perceptual Spread (Bark)           |\n",
    "| Brightness/Sharpness| Centroid, Slope        | Sharpness (Weighted High Bands)    |\n",
    "| Pitch Content       | Chroma, Centroid       | MFCCs, Mel-scale representation     |\n",
    "\n",
    "---\n",
    "\n",
    "## Slope vs Skewness Explained\n",
    "\n",
    "You can have:\n",
    "\n",
    "- üîπ **Flat spectrum, skewed**  \n",
    "  - **Slope = 0** ‚Üí No linear trend (flat average tilt)  \n",
    "  - **Skew ‚â† 0** ‚Üí Energy is bunched to one side of the mean  \n",
    "  - üß† *Imagine a spectrum with two big peaks off-center but an equal dip in the middle ‚Äî average tilt is zero, but energy isn't symmetrically placed.*\n",
    "\n",
    "- üîπ **Sloped spectrum, symmetric**  \n",
    "  - **Slope ‚â† 0** ‚Üí Energy trends down (or up) across frequencies  \n",
    "  - **Skew = 0** ‚Üí Energy is symmetrically spread around the mean frequency  \n",
    "  - üß† *Imagine a steadily descending ramp of frequencies ‚Äî it slopes, but the energy on either side of the center is balanced in shape.*\n",
    "\n",
    "### Analogy: The Seesaw  \n",
    "- **Slope** = whether the whole seesaw is tilted.  \n",
    "- **Skewness** = whether the mass (energy) is unevenly distributed even if the seesaw is level."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNwPj2Nm5fxiUqxy3QukFf3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
